<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Final Combined Ranking (22/12/2024)</title>
  <style>
    body {
      font-family: sans-serif;
      margin: 2rem;
      line-height: 1.4;
    }
    h1 {
      margin-bottom: 0.5rem;
    }
    h2 {
      margin-top: 2rem;
      margin-bottom: 0.25rem;
    }
    .composite {
      font-style: italic;
      font-size: 90%;
    }
    .tag {
      color: #b00; /* a mild highlight color */
      font-weight: bold;
    }
    ol {
      margin: 0;
      padding-left: 2rem;
    }
  </style>
</head>

<body>

<h1>Final Combined Ranking (22/12/2024)</h1>

<ol>
  <li>
    <strong>o3</strong> 
    <span class="tag">(early ASI)</span> 
    <span class="composite">, composite ~1.000</span>
  </li>
  <li>
    <strong>ChatGPT o1 Pro</strong>
    <span class="tag">(early ASI)</span>
  </li>
  <li>
    <strong>ChatGPT o1</strong>
    <span class="composite">, composite ~0.840</span>
  </li>
  <li>
    <strong>o3 mini (High)</strong>
    <span class="composite">, composite ~0.642</span>
  </li>
  <li>
    <strong>o3 mini (Med)</strong>
    <span class="composite">, composite ~0.626</span>
  </li>
  <li>
    <strong>o3 mini (Avg)</strong>
    <span class="composite">, composite ~0.612</span>
  </li>
  <li>
    <strong>o3 mini (Low)</strong>
    <span class="composite">, composite ~0.568</span>
  </li>
  <li>ChatGPT o1 Preview (o1-preview-2024-09-12): 65.79</li>
  <li>DeepSeek Chain of Thought (Ordinal placement, no score)</li>
  <li>Gemini Pro 2.0 1206 (gemini-exp-1206): 64.09</li>
  <li>Gemini 2.0 Flash Thinking Exp (gemini-2.0-flash-thinking-exp-1219): 61.57</li>
  <li>Gemini 2.0 Flash Exp (gemini-2.0-flash-exp): 59.26</li>
  <li>Claude 3.5 Sonnet (20241022) (claude-3-5-sonnet-20241022): 59.03</li>
  <li>Claude 3.5 Sonnet (20240620) (claude-3-5-sonnet-20240620): 58.74</li>
  <li>ChatGPT o1 mini (o1-mini-2024-09-12): 57.76</li>
  <li>Gemini Exp 1121 (gemini-exp-1121): 57.36</li>
  <li>GPT-4o (gpt-4o-2024-08-06): 55.33</li>
  <li>GPT-4o (gpt-4o-2024-05-13): 54.41</li>
  <li>Gemini 1.5 Pro (gemini-1.5-pro-002): 54.33</li>
  <li>Grok (grok-2-1212): 54.30</li>
  <li>Gemini 1.5 Pro Exp (gemini-1.5-pro-exp-0827): 53.29</li>
  <li>Meta Llama 3.1 405b Turbo (meta-llama-3.1-405b-instruct-turbo): 52.36</li>
  <li>GPT-4o (gpt-4o-2024-11-20): 52.19</li>
  <li>LearnLM 1.5 Pro Experimental (learnlm-1.5-pro-experimental): 52.19</li>
  <li>ChatGPT-4o-latest-0903 (chatgpt-4o-latest-0903): 51.66</li>
  <li>Qwen2.5-72b-Instruct-Turbo (qwen2.5-72b-instruct-turbo): 51.44</li>
  <li>GPT-4 Turbo (gpt-4-turbo-2024-04-09): 50.40</li>
  <li>Llama 3.3 70b Turbo (llama-3.3-70b-instruct-turbo): 50.16</li>
  <li>Grok Beta (grok-beta): 49.18</li>
  <li>Claude 3 Opus (claude-3-opus-20240229): 49.12</li>
  <li>Gemini 1.5 Flash (gemini-1.5-flash-002): 48.59</li>
  <li>Mistral Large 2411 (mistral-large-2411): 48.43</li>
  <li>Mistral Large 2407 (mistral-large-2407): 48.31</li>
  <li>Qwen2.5-Coder-32b-Instruct (qwen2.5-coder-32b-instruct): 46.23</li>
  <li>DeepSeek v2.5 (deepseek-v2.5-1210): 45.98</li>
  <li>GPT-4-0125-preview (gpt-4-0125-preview): 45.71</li>
  <li>Gemini 1.5 Flash Exp (gemini-1.5-flash-exp-0827): 45.21</li>
  <li>Meta Llama 3.1 70b Turbo (meta-llama-3.1-70b-instruct-turbo): 44.89</li>
  <li>Gemini 1.5 Pro 001 (gemini-1.5-pro-001): 44.22</li>
  <li>Amazon Nova Pro (amazon.nova-pro-v1:0): 43.55</li>
  <li>Claude 3.5 Haiku (20241022) (claude-3-5-haiku-20241022): 43.45</li>
  <li>GPT-4o Mini (gpt-4o-mini-2024-07-18): 41.26</li>
  <li>Qwq-32b-preview (qwq-32b-preview): 39.90</li>
  <li>Gemini 1.5 Flash 001 (gemini-1.5-flash-001): 39.22</li>
  <li>Gemma 2 27b It (gemma-2-27b-it): 38.19</li>
  <li>Gemini 1.5 Flash 8b Exp 0827 (gemini-1.5-flash-8b-exp-0827): 36.67</li>
  <li>Amazon Nova Lite (amazon.nova-lite-v1:0): 36.35</li>
  <li>Gemini 1.5 Flash 8b Exp 0924 (gemini-1.5-flash-8b-exp-0924): 36.01</li>
  <li>Qwen2.5-7b-Instruct-Turbo (qwen2.5-7b-instruct-turbo): 34.90</li>
  <li>Claude 3 Haiku (20240307) (claude-3-haiku-20240307): 33.85</li>
  <li>Mistral Small 2409 (mistral-small-2409): 33.39</li>
  <li>Mixtral-8x22b-Instruct-v0.1 (mixtral-8x22b-instruct-v0.1): 32.45</li>
  <li>Command-r-plus-08-2024 (command-r-plus-08-2024): 31.76</li>
  <li>Amazon Nova Micro (amazon.nova-micro-v1:0): 29.56</li>
  <li>Gemma 2 9b It (gemma-2-9b-it): 28.66</li>
  <li>Mistral Small 2402 (mistral-small-2402): 28.36</li>
  <li>Command-r-08-2024 (command-r-08-2024): 27.31</li>
  <li>Command-r-plus-04-2024 (command-r-plus-04-2024): 27.11</li>
  <li>Meta Llama 3.1 8b Turbo (meta-llama-3.1-8b-instruct-turbo): 25.97</li>
  <li>Phi-3-Small-8k-Instruct (phi-3-small-8k-instruct): 24.03</li>
  <li>Phi-3-Mini-128k-Instruct (phi-3-mini-128k-instruct): 22.36</li>
  <li>Olmo-2-1124-13b-Instruct (olmo-2-1124-13b-instruct): 22.09</li>
  <li>Phi-3-Mini-4k-Instruct (phi-3-mini-4k-instruct): 22.08</li>
</ol>

</body>
</html>
