<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Network Taxonomy - Post-Transformer AGI Lineage</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&family=Space+Grotesk:wght@400;700&display=swap');
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        :root {
            --bg-dark: #0a0a0f;
            --bg-card: #12121a;
            --border: #2a2a3a;
            --text: #e0e0e8;
            --text-dim: #7a7a8a;
            --accent-green: #00ff88;
            --accent-cyan: #00d4ff;
            --accent-purple: #a855f7;
            --accent-orange: #ff8800;
            --accent-pink: #ff0088;
            --accent-yellow: #ffdd00;
        }
        
        body {
            font-family: 'JetBrains Mono', monospace;
            background: var(--bg-dark);
            color: var(--text);
            min-height: 100vh;
            padding: 2rem;
            background-image: 
                radial-gradient(circle at 20% 50%, rgba(0, 255, 136, 0.03) 0%, transparent 50%),
                radial-gradient(circle at 80% 80%, rgba(0, 212, 255, 0.03) 0%, transparent 50%);
        }
        
        header {
            text-align: center;
            margin-bottom: 3rem;
            padding-bottom: 2rem;
            border-bottom: 1px solid var(--border);
        }
        
        h1 {
            font-family: 'Space Grotesk', sans-serif;
            font-size: 2.5rem;
            font-weight: 700;
            background: linear-gradient(135deg, var(--accent-green), var(--accent-cyan));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 0.5rem;
        }
        
        .subtitle {
            color: var(--text-dim);
            font-size: 0.9rem;
        }
        
        .legend {
            display: flex;
            justify-content: center;
            gap: 2rem;
            margin-top: 1.5rem;
            flex-wrap: wrap;
        }
        
        .legend-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            font-size: 0.75rem;
            color: var(--text-dim);
        }
        
        .legend-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
        }
        
        .tree-container {
            max-width: 1400px;
            margin: 0 auto;
        }
        
        .tree {
            padding-left: 0;
        }
        
        .tree ul {
            padding-left: 2rem;
            border-left: 1px dashed var(--border);
            margin-left: 0.5rem;
        }
        
        .tree li {
            list-style: none;
            position: relative;
            padding: 0.5rem 0;
        }
        
        .node {
            display: inline-flex;
            align-items: center;
            gap: 0.75rem;
            padding: 0.75rem 1.25rem;
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.2s ease;
            max-width: 100%;
        }
        
        .node:hover {
            border-color: var(--accent-cyan);
            box-shadow: 0 0 20px rgba(0, 212, 255, 0.1);
            transform: translateX(4px);
        }
        
        .node.expanded {
            border-color: var(--accent-green);
            box-shadow: 0 0 15px rgba(0, 255, 136, 0.1);
        }
        
        .node-indicator {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            flex-shrink: 0;
        }
        
        .node-indicator.existing { background: var(--accent-green); }
        .node-indicator.hybrid { background: var(--accent-cyan); }
        .node-indicator.experimental { background: var(--accent-purple); }
        .node-indicator.projected { background: var(--accent-orange); }
        .node-indicator.theoretical { background: var(--accent-pink); }
        .node-indicator.root { background: var(--accent-yellow); }
        
        .node-content {
            display: flex;
            flex-direction: column;
            gap: 0.25rem;
        }
        
        .node-name {
            font-weight: 700;
            font-size: 0.95rem;
            color: var(--text);
        }
        
        .node-meta {
            font-size: 0.7rem;
            color: var(--text-dim);
        }
        
        .node-year {
            color: var(--accent-cyan);
            margin-right: 0.5rem;
        }
        
        .node-desc {
            opacity: 0.7;
        }
        
        .toggle {
            font-size: 0.8rem;
            color: var(--accent-green);
            margin-left: auto;
            padding-left: 1rem;
        }
        
        .children {
            display: none;
            animation: fadeIn 0.3s ease;
        }
        
        .children.visible {
            display: block;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        .stats {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 1rem;
            font-size: 0.75rem;
        }
        
        .stats-title {
            color: var(--accent-green);
            margin-bottom: 0.5rem;
        }
        
        @media (max-width: 768px) {
            body { padding: 1rem; }
            h1 { font-size: 1.5rem; }
            .tree ul { padding-left: 1rem; }
            .node { padding: 0.5rem 0.75rem; }
            .stats { display: none; }
        }
    </style>
</head>
<body>
    <header>
        <h1>Neural Network Taxonomy</h1>
        <p class="subtitle">Evolutionary tree from Transformer (2017) â†’ Future AGI architectures</p>
        <div class="legend">
            <div class="legend-item"><div class="legend-dot" style="background: var(--accent-yellow)"></div> Root/Foundation</div>
            <div class="legend-item"><div class="legend-dot" style="background: var(--accent-green)"></div> Existing/Deployed</div>
            <div class="legend-item"><div class="legend-dot" style="background: var(--accent-cyan)"></div> Hybrid Architecture</div>
            <div class="legend-item"><div class="legend-dot" style="background: var(--accent-purple)"></div> Experimental</div>
            <div class="legend-item"><div class="legend-dot" style="background: var(--accent-orange)"></div> Projected</div>
            <div class="legend-item"><div class="legend-dot" style="background: var(--accent-pink)"></div> Theoretical</div>
        </div>
    </header>
    
    <div class="tree-container">
        <ul class="tree" id="tree"></ul>
    </div>
    
    <div class="stats">
        <div class="stats-title">// STATS</div>
        <div id="stats-content"></div>
    </div>

    <script>
        // ===========================================
        // NEURAL NETWORK TAXONOMY DATA
        // Edit this to add/modify nodes!
        // ===========================================
        
        const taxonomy = {
            name: "Transformer",
            year: 2017,
            desc: "Attention Is All You Need - First AGI-capable architecture",
            type: "root",
            children: [
                {
                    name: "Autoregressive (Decoder-Only)",
                    year: 2018,
                    desc: "GPT lineage - causal language modeling",
                    type: "existing",
                    children: [
                        {
                            name: "GPT-1",
                            year: 2018,
                            desc: "117M params - proof of concept",
                            type: "existing"
                        },
                        {
                            name: "GPT-2",
                            year: 2019,
                            desc: "1.5B params - emergent capabilities",
                            type: "existing"
                        },
                        {
                            name: "GPT-3",
                            year: 2020,
                            desc: "175B params - few-shot learning",
                            type: "existing",
                            children: [
                                {
                                    name: "InstructGPT / ChatGPT",
                                    year: 2022,
                                    desc: "RLHF fine-tuning",
                                    type: "existing"
                                },
                                {
                                    name: "GPT-4",
                                    year: 2023,
                                    desc: "Multimodal, likely MoE",
                                    type: "existing"
                                }
                            ]
                        },
                        {
                            name: "LLaMA Lineage",
                            year: 2023,
                            desc: "Open weights revolution",
                            type: "existing",
                            children: [
                                { name: "LLaMA 2", year: 2023, desc: "Commercial open weights", type: "existing" },
                                { name: "LLaMA 3", year: 2024, desc: "Competitive with frontier", type: "existing" },
                                { name: "Mistral / Mixtral", year: 2023, desc: "Efficient open MoE", type: "existing" }
                            ]
                        },
                        {
                            name: "Claude Series",
                            year: 2023,
                            desc: "Constitutional AI training",
                            type: "existing",
                            children: [
                                { name: "Claude 3 (Opus/Sonnet/Haiku)", year: 2024, desc: "Tiered capability", type: "existing" },
                                { name: "Claude 4.5 (Opus)", year: 2025, desc: "Current frontier", type: "existing" }
                            ]
                        }
                    ]
                },
                {
                    name: "Encoder-Only",
                    year: 2018,
                    desc: "Bidirectional - masked prediction",
                    type: "existing",
                    children: [
                        { name: "BERT", year: 2018, desc: "Bidirectional representations", type: "existing" },
                        { name: "RoBERTa", year: 2019, desc: "Optimized BERT training", type: "existing" },
                        { name: "DeBERTa", year: 2020, desc: "Disentangled attention", type: "existing" }
                    ]
                },
                {
                    name: "Encoder-Decoder",
                    year: 2019,
                    desc: "Seq2seq with attention",
                    type: "existing",
                    children: [
                        { name: "T5", year: 2019, desc: "Text-to-text framework", type: "existing" },
                        { name: "BART", year: 2019, desc: "Denoising autoencoder", type: "existing" },
                        { name: "Flan-T5", year: 2022, desc: "Instruction-tuned T5", type: "existing" }
                    ]
                },
                {
                    name: "Sparse / Efficient Attention",
                    year: 2020,
                    desc: "Breaking quadratic complexity",
                    type: "existing",
                    children: [
                        { name: "Longformer", year: 2020, desc: "Local + global attention", type: "existing" },
                        { name: "BigBird", year: 2020, desc: "Sparse random attention", type: "existing" },
                        { name: "Flash Attention", year: 2022, desc: "IO-aware exact attention", type: "existing" },
                        { name: "Ring Attention", year: 2023, desc: "Distributed long context", type: "existing" }
                    ]
                },
                {
                    name: "Mixture of Experts (MoE)",
                    year: 2021,
                    desc: "Conditional computation",
                    type: "existing",
                    children: [
                        { name: "Switch Transformer", year: 2021, desc: "Simplified routing", type: "existing" },
                        { name: "GLaM", year: 2021, desc: "1.2T params, 97B active", type: "existing" },
                        { name: "Mixtral 8x7B", year: 2023, desc: "Open MoE", type: "existing" },
                        { name: "DeepSeek MoE", year: 2024, desc: "Fine-grained experts", type: "existing" }
                    ]
                },
                {
                    name: "State Space Models (SSM)",
                    year: 2021,
                    desc: "Linear recurrence alternative",
                    type: "hybrid",
                    children: [
                        { name: "S4", year: 2021, desc: "Structured state spaces", type: "existing" },
                        { name: "H3", year: 2022, desc: "Hungry Hungry Hippos", type: "existing" },
                        {
                            name: "Mamba",
                            year: 2023,
                            desc: "Selective state spaces",
                            type: "existing",
                            children: [
                                { name: "Mamba-2", year: 2024, desc: "Improved efficiency", type: "existing" },
                                { name: "Jamba", year: 2024, desc: "Mamba + Transformer hybrid", type: "hybrid" },
                                {
                                    name: "NAT-Mamba Variants",
                                    year: 2024,
                                    desc: "Non-autoregressive Mamba",
                                    type: "experimental",
                                    children: [
                                        { name: "NAT-Mamba-CTC", year: null, desc: "CTC loss variant", type: "experimental" },
                                        { name: "NAT-Mamba-Iterative", year: null, desc: "Iterative refinement", type: "experimental" }
                                    ]
                                }
                            ]
                        },
                        { name: "RWKV", year: 2023, desc: "RNN-Transformer hybrid", type: "existing" }
                    ]
                },
                {
                    name: "Non-Autoregressive (NAT)",
                    year: 2018,
                    desc: "Parallel generation",
                    type: "existing",
                    children: [
                        { name: "NAT (Original)", year: 2018, desc: "Fertility prediction", type: "existing" },
                        { name: "Mask-Predict", year: 2019, desc: "Iterative refinement", type: "existing" },
                        { name: "CMLM", year: 2019, desc: "Conditional masked LM", type: "existing" },
                        {
                            name: "Semi-Autoregressive (SAT)",
                            year: 2018,
                            desc: "Chunk-parallel generation",
                            type: "existing",
                            children: [
                                {
                                    name: "AR+SAT Joint Training",
                                    year: 2024,
                                    desc: "AGILLM-3 architecture",
                                    type: "experimental",
                                    children: [
                                        { name: "AGILLM-3", year: 2025, desc: "OpenTransformers - 900k+ steps", type: "experimental" }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    name: "Memory-Augmented",
                    year: 2019,
                    desc: "External memory integration",
                    type: "hybrid",
                    children: [
                        { name: "Compressive Transformer", year: 2019, desc: "Compressed memory", type: "existing" },
                        { name: "Memorizing Transformers", year: 2022, desc: "kNN retrieval", type: "existing" },
                        {
                            name: "Transformer-NTM Hybrids",
                            year: null,
                            desc: "Neural Turing Machine fusion",
                            type: "experimental",
                            children: [
                                { name: "Memory-Attention Networks", year: null, desc: "Differentiable memory", type: "experimental" }
                            ]
                        }
                    ]
                },
                {
                    name: "Multimodal",
                    year: 2021,
                    desc: "Cross-modal understanding",
                    type: "existing",
                    children: [
                        { name: "CLIP", year: 2021, desc: "Image-text contrastive", type: "existing" },
                        { name: "DALL-E / Stable Diffusion", year: 2021, desc: "Text-to-image", type: "existing" },
                        { name: "Flamingo", year: 2022, desc: "Few-shot visual learning", type: "existing" },
                        { name: "GPT-4V", year: 2023, desc: "Native vision", type: "existing" },
                        { name: "Gemini", year: 2023, desc: "Native multimodal", type: "existing" }
                    ]
                },
                {
                    name: "PROJECTED FUTURE",
                    year: null,
                    desc: "Speculative architectures",
                    type: "projected",
                    children: [
                        {
                            name: "Hybrid AR+NAT Production",
                            year: "2025+",
                            desc: "Joint training at scale",
                            type: "projected"
                        },
                        {
                            name: "Continuous Token Spaces",
                            year: "2026+",
                            desc: "Beyond discrete tokens",
                            type: "projected"
                        },
                        {
                            name: "Native Reasoning Architectures",
                            year: "2026+",
                            desc: "Built-in chain-of-thought",
                            type: "projected"
                        },
                        {
                            name: "World Model Integration",
                            year: "2027+",
                            desc: "Predictive world simulation",
                            type: "theoretical"
                        },
                        {
                            name: "Post-Transformer Paradigm",
                            year: "???",
                            desc: "Successor architecture",
                            type: "theoretical"
                        }
                    ]
                }
            ]
        };

        // ===========================================
        // RENDERING LOGIC
        // ===========================================
        
        function createNode(data, depth = 0) {
            const li = document.createElement('li');
            
            const node = document.createElement('div');
            node.className = 'node';
            if (data.children && data.children.length > 0) {
                node.classList.add('has-children');
            }
            
            const indicator = document.createElement('div');
            indicator.className = `node-indicator ${data.type}`;
            
            const content = document.createElement('div');
            content.className = 'node-content';
            
            const name = document.createElement('div');
            name.className = 'node-name';
            name.textContent = data.name;
            
            const meta = document.createElement('div');
            meta.className = 'node-meta';
            
            if (data.year) {
                const year = document.createElement('span');
                year.className = 'node-year';
                year.textContent = data.year;
                meta.appendChild(year);
            }
            
            if (data.desc) {
                const desc = document.createElement('span');
                desc.className = 'node-desc';
                desc.textContent = data.desc;
                meta.appendChild(desc);
            }
            
            content.appendChild(name);
            content.appendChild(meta);
            
            node.appendChild(indicator);
            node.appendChild(content);
            
            if (data.children && data.children.length > 0) {
                const toggle = document.createElement('span');
                toggle.className = 'toggle';
                toggle.textContent = `[+${data.children.length}]`;
                node.appendChild(toggle);
                
                const childrenUl = document.createElement('ul');
                childrenUl.className = 'children';
                
                data.children.forEach(child => {
                    childrenUl.appendChild(createNode(child, depth + 1));
                });
                
                node.addEventListener('click', (e) => {
                    e.stopPropagation();
                    const isVisible = childrenUl.classList.toggle('visible');
                    node.classList.toggle('expanded', isVisible);
                    toggle.textContent = isVisible ? `[-${data.children.length}]` : `[+${data.children.length}]`;
                });
                
                li.appendChild(node);
                li.appendChild(childrenUl);
            } else {
                li.appendChild(node);
            }
            
            return li;
        }
        
        function countNodes(data) {
            let count = 1;
            if (data.children) {
                data.children.forEach(child => {
                    count += countNodes(child);
                });
            }
            return count;
        }
        
        function countByType(data, types = {}) {
            types[data.type] = (types[data.type] || 0) + 1;
            if (data.children) {
                data.children.forEach(child => countByType(child, types));
            }
            return types;
        }
        
        // Initialize
        document.getElementById('tree').appendChild(createNode(taxonomy));
        
        const types = countByType(taxonomy);
        const statsHtml = Object.entries(types)
            .map(([type, count]) => `${type}: ${count}`)
            .join('<br>');
        document.getElementById('stats-content').innerHTML = 
            `Total: ${countNodes(taxonomy)}<br>${statsHtml}`;
    </script>
</body>
</html>
